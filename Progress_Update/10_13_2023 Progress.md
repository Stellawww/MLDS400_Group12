# October 13th Progress Update
## What we did
- Imported five tables into Jupyter Notebook for a preliminary check.
- Completed a first-round of cleaning but will require further data wrangling.

### deptinfo (Department Info)
- Two columns (`deptid`, `deptdesc`)
- 60 non-null rows
- There was no key insight to draw from this small table. It will be primarily used to join with `skuinfo` table.

### strinfo (Store Info)
- Four columns (`storeid`,`city`,`state`,`zip`)
- 453 non-null rows.
- Although there are 50 states in the United States, we discovered that the table only includes 31 unique states.
- While we will use `storeid` to join tables, it is good to note that not all US states are available.

### skstinfo (SKU + Store Info)
- Four columns (`skuid`,`storeid`,`cost`,`retail`)
- Close to 2.5 million rows of data
- `cost`: Mean = $24.16, Stand Dev. = $40.57
- `retail`: Mean = $43.33, Stand Dev. = $83.92

### trans (Transaction)
- Currently in the process of identifying correct column names. There are a total of 12 columns.
- Around 681K rows of data.

### skuinfo (SKU Info)
- Total of 10 columns before column filter (`skuid`,`deptid`,`classid`,`upc`,`style`,`color`,`size`,`packsize`,`vendor`,`brand`).
- Excluded `classid`, `upc`, `vendor` after checking DB schema definition (No good insight will be extracted from these three columns).
- There are around 781k rows of data.
- `packsize` is a mixture of numeric values and strings. (Ex. 6 vs BIZARRE) The DB Schema data dictionary says that this variable is supposed to be a numeric digit.


## Our plan for next week
- Continue cleaning up the data and working on the EDA.
- Attempt to import the data into SQL Server, if possible. (It takes a substantial kernel pressure to run in Jupyter Notebook, causing a crash oftentimes).
